# -*- coding: utf-8 -*-
"""Retail Sales Forecasting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PE_wINvUdez31df2XcIkCRgsewDbZ8L5

the first step is loading all the required libraries and upload the dataset and Prepare the data before building the model
"""

pip install pmdarima

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pmdarima.arima import auto_arima
from statsmodels.tsa.statespace.sarimax import SARIMAX
import math
from keras.models import Sequential
from keras.layers import Dense
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error , r2_score
from keras.layers import LSTM, Flatten

data =pd.read_csv('Cairo.csv')
data.shape

data.head()

data.info()

data['PRODUCT_CODE'] = data['PRODUCT_CODE'].astype(str)

data.describe()

"""Data Exploration"""

subcategory_sales = data.groupby('Category')['Total Price'].sum()
subcategory_sales.plot(kind='pie')
plt.xlabel('Category')
plt.ylabel('Total Sales')
plt.show()

subcategory_sales = data.groupby('subcategory')['Total Price'].sum()
subcategory_sales.plot(kind='bar')
plt.xlabel('Subcategory')
plt.ylabel('Total Sales')
plt.show()

correlation_matrix = data[['Quantity', 'Price_Per_Piece', 'Total Price']].corr()
plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='nearest')
plt.colorbar()
plt.xticks(range(correlation_matrix.shape[1]), correlation_matrix.columns, rotation=45)
plt.yticks(range(correlation_matrix.shape[1]), correlation_matrix.columns)
plt.show()

"""Data Manipulation

"""

#Filter by category
category_name = 'Soap'
filtered_df = data[data['Category'] == category_name]

columns_to_drop = ['PRODUCT_CODE', 'Category','Price_Per_Piece', 'Quantity','subcategory']
filtered_df = data.drop(columns=columns_to_drop)

filtered_df.info()

filtered_df

#Time series analysis
filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])
filtered_df.set_index('Date', inplace=True)
weekly_sales = filtered_df['Total Price'].resample('W').sum()
plt.plot(weekly_sales)
plt.xlabel('Week')
plt.ylabel('Total Sales')
plt.show()

weekly_sales = pd.DataFrame(weekly_sales)

"""Models

ARIMA
"""

arima_model = auto_arima(weekly_sales['Total Price'], start_p = 1, d=1, start_q = 1,
                          max_p = 5, max_q = 5, max_d=5, m = 12,
                          start_P = 0, D=1, start_Q=0, max_P=5, max_D=5, max_Q=5,
                          seasonal = True,
                          trace = True,
                          error_action ='ignore',
                          suppress_warnings = True,
                          stepwise = True, n_fits=50)

print(arima_model.summary() )

size = int(len(weekly_sales) * 0.66)
X_train, X_test = weekly_sales[0:size], weekly_sales[size:len(weekly_sales)]

model = SARIMAX(X_train['Total Price'],
                order = (0, 1, 3),
                seasonal_order =(0, 1, 1, 12))

result = model.fit()
result.summary()


#Train prediction
start_index = 0
end_index = len(X_train)-1
train_prediction = result.predict(start_index, end_index)

#Prediction
start_index = len(X_train)
end_index = len(weekly_sales)-1
prediction = result.predict(start_index, end_index).rename('Predicted Total Price')

# calculate root mean squared error and R^2
trainScore = math.sqrt(mean_squared_error(X_train, train_prediction))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(X_test, prediction))
print('Test Score: %.2f RMSE' % (testScore))
score = r2_score(X_test, prediction)
print("R2 score is: ", score)


forecast = result.predict(start = len(weekly_sales),
                          end = (len(weekly_sales)-1) + 3 * 12,
                          typ = 'levels').rename('Forecast')
# plot predictions and actual values
prediction.plot(legend = True)
X_test['Total Price'].plot(legend = True)

"""Prepare the data foe FFNN Model and LSTM mosel

Normalization
"""

scaler = MinMaxScaler(feature_range=(0, 1))
weekly_sales = scaler.fit_transform(weekly_sales)

"""Data Splitting"""

train_size = int(len(weekly_sales) * 0.66)
test_size = len(weekly_sales) - train_size
train, test = weekly_sales[0:train_size,:], weekly_sales[train_size:len(weekly_sales),:]
def to_sequences(weekly_sales, seq_size=1):
    x = []
    y = []

    for i in range(len(weekly_sales)-seq_size-1):
        #print(i)
        window = weekly_sales[i:(i+seq_size), 0]
        x.append(window)
        y.append(weekly_sales[i+seq_size, 0])

    return np.array(x),np.array(y)
seq_size = 10 # Number of time steps to look back
trainX, trainY = to_sequences(train, seq_size)
testX, testY = to_sequences(test, seq_size)
print("Shape of training set: {}".format(trainX.shape))
print("Shape of test set: {}".format(testX.shape))

"""FFNN"""

# create and fit dense model
model = Sequential()
model.add(Dense(64, input_dim=seq_size, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['acc'])
print(model.summary())

#Training Model
model.fit(trainX, trainY, validation_data=(testX, testY),
          verbose=2, epochs=500)

# make predictions
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
trainPredict = scaler.inverse_transform(trainPredict)
trainY_inverse = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY_inverse = scaler.inverse_transform([testY])

#Evaluation Model
trainScore = math.sqrt(mean_squared_error(trainY_inverse[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY_inverse[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

# invert predictions back to prescaled values
trainPredictPlot = np.empty_like(weekly_sales)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = trainPredict
testPredictPlot = np.empty_like(weekly_sales)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict)+(seq_size*2)+1:len(weekly_sales)-1, :] = testPredict

# plot baseline and predictions
plt.plot(scaler.inverse_transform(weekly_sales))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()

"""LSTM"""

#Stacked LSTM with 1 hidden dense layer
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

model = Sequential()
model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(None, seq_size)))
model.add(LSTM(50, activation='relu'))
model.add(Dense(32))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')

model.summary()

#Training Model
model.fit(trainX, trainY, validation_data=(testX, testY),
          verbose=2, epochs=100)


# make predictions

trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

# invert predictions back to prescaled values
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([testY])

# Evaluation Model
trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))

testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

# invert predictions back to prescaled values
trainPredictPlot = np.empty_like(weekly_sales)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = trainPredict
testPredictPlot = np.empty_like(weekly_sales)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict)+(seq_size*2)+1:len(weekly_sales)-1, :] = testPredict

# plot baseline and predictions
plt.plot(scaler.inverse_transform(weekly_sales))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()

dataQ= pd.read_csv('Cairo.csv')

dataQ.head()

#Filter by category
category_name = 'BS 165'
filtered_df = dataQ[dataQ['Category'] == category_name]

columns_to_drop = ['PRODUCT_CODE', 'Category','Price_Per_Piece','Total Price']
filtered_df = dataQ.drop(columns=columns_to_drop)

#Time series analysis
filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])
filtered_df.set_index('Date', inplace=True)
weekly_sales = filtered_df['Quantity'].resample('W').sum()
plt.plot(weekly_sales)
plt.xlabel('Week')
plt.ylabel('Quantity')
plt.show()

weekly_sales.info()

weekly_sales.head()

"""FFNN for Prediction Quantinty"""

weekly_sales = pd.DataFrame(weekly_sales)

scaler = MinMaxScaler(feature_range=(0, 1))
weekly_sales = scaler.fit_transform(weekly_sales)
train_size = int(len(weekly_sales) * 0.66)
test_size = len(weekly_sales) - train_size
train, test = weekly_sales[0:train_size,:], weekly_sales[train_size:len(weekly_sales),:]
def to_sequences(weekly_sales, seq_size=1):
    x = []
    y = []

    for i in range(len(weekly_sales)-seq_size-1):
        #print(i)
        window = weekly_sales[i:(i+seq_size), 0]
        x.append(window)
        y.append(weekly_sales[i+seq_size, 0])

    return np.array(x),np.array(y)
seq_size = 10 # Number of time steps to look back
trainX, trainY = to_sequences(train, seq_size)
testX, testY = to_sequences(test, seq_size)
print("Shape of training set: {}".format(trainX.shape))
print("Shape of test set: {}".format(testX.shape))
# create and fit dense model
model = Sequential()
model.add(Dense(64, input_dim=seq_size, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['acc'])
print(model.summary())
#Training Model
model.fit(trainX, trainY, validation_data=(testX, testY),
          verbose=2, epochs=100)
# make predictions
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
trainPredict = scaler.inverse_transform(trainPredict)
trainY_inverse = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY_inverse = scaler.inverse_transform([testY])
#Evaluation Model
trainScore = math.sqrt(mean_squared_error(trainY_inverse[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY_inverse[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))
# invert predictions back to prescaled values
trainPredictPlot = np.empty_like(weekly_sales)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = trainPredict
testPredictPlot = np.empty_like(weekly_sales)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict)+(seq_size*2)+1:len(weekly_sales)-1, :] = testPredict
# plot baseline and predictions
plt.plot(scaler.inverse_transform(weekly_sales))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()